{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named keras",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-01b827af7a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named keras"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/asilomar_nov182017_all.csv')\n",
    "# this is actually [u1, v1, u2, v2]\n",
    "X = df_train[['u','v','w','h']]\n",
    "y = df_train['distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2d52967d6e5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.30)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_regression_neural_net():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(NUM_FEATURES*4, input_dim=NUM_FEATURES, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11088 samples, validate on 4753 samples\n",
      "Epoch 1/30\n",
      "11088/11088 [==============================] - 1s 75us/step - loss: 1015.6877 - val_loss: 169.0422\n",
      "Epoch 2/30\n",
      "11088/11088 [==============================] - 1s 57us/step - loss: 162.2113 - val_loss: 150.5284\n",
      "Epoch 3/30\n",
      "11088/11088 [==============================] - 0s 43us/step - loss: 150.8732 - val_loss: 139.1187\n",
      "Epoch 4/30\n",
      "11088/11088 [==============================] - 1s 45us/step - loss: 140.5577 - val_loss: 128.4612\n",
      "Epoch 5/30\n",
      "11088/11088 [==============================] - 0s 44us/step - loss: 128.3986 - val_loss: 117.0210\n",
      "Epoch 6/30\n",
      "11088/11088 [==============================] - 1s 46us/step - loss: 120.3449 - val_loss: 109.5576\n",
      "Epoch 7/30\n",
      "11088/11088 [==============================] - 1s 55us/step - loss: 112.6414 - val_loss: 105.9063\n",
      "Epoch 8/30\n",
      "11088/11088 [==============================] - 1s 55us/step - loss: 108.6662 - val_loss: 109.4086\n",
      "Epoch 9/30\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 105.6482 - val_loss: 99.7117\n",
      "Epoch 10/30\n",
      "11088/11088 [==============================] - 1s 45us/step - loss: 103.2657 - val_loss: 104.2099\n",
      "Epoch 11/30\n",
      "11088/11088 [==============================] - 1s 46us/step - loss: 102.8811 - val_loss: 95.0987\n",
      "Epoch 12/30\n",
      "11088/11088 [==============================] - 1s 59us/step - loss: 102.2891 - val_loss: 101.7041\n",
      "Epoch 13/30\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 101.2161 - val_loss: 94.3068\n",
      "Epoch 14/30\n",
      "11088/11088 [==============================] - 1s 61us/step - loss: 101.2621 - val_loss: 96.4744\n",
      "Epoch 15/30\n",
      "11088/11088 [==============================] - 1s 46us/step - loss: 100.1753 - val_loss: 93.4998\n",
      "Epoch 16/30\n",
      "11088/11088 [==============================] - 1s 45us/step - loss: 98.2420 - val_loss: 92.3592\n",
      "Epoch 17/30\n",
      "11088/11088 [==============================] - 1s 50us/step - loss: 97.4617 - val_loss: 93.4934\n",
      "Epoch 18/30\n",
      "11088/11088 [==============================] - 1s 54us/step - loss: 98.5291 - val_loss: 96.8401\n",
      "Epoch 19/30\n",
      "11088/11088 [==============================] - 1s 50us/step - loss: 98.2272 - val_loss: 93.1109\n",
      "Epoch 20/30\n",
      "11088/11088 [==============================] - 1s 47us/step - loss: 96.8513 - val_loss: 91.1255\n",
      "Epoch 21/30\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 96.4984 - val_loss: 101.5088\n",
      "Epoch 22/30\n",
      "11088/11088 [==============================] - 1s 46us/step - loss: 95.9956 - val_loss: 99.1510\n",
      "Epoch 23/30\n",
      "11088/11088 [==============================] - 1s 46us/step - loss: 95.6225 - val_loss: 89.8868\n",
      "Epoch 24/30\n",
      "11088/11088 [==============================] - 1s 49us/step - loss: 97.3116 - val_loss: 89.8478\n",
      "Epoch 25/30\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 95.8530 - val_loss: 95.2658\n",
      "Epoch 26/30\n",
      "11088/11088 [==============================] - 0s 43us/step - loss: 94.5291 - val_loss: 90.0711\n",
      "Epoch 27/30\n",
      "11088/11088 [==============================] - 1s 47us/step - loss: 94.1214 - val_loss: 90.7326\n",
      "Epoch 28/30\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 93.7822 - val_loss: 88.1570\n",
      "Epoch 29/30\n",
      "11088/11088 [==============================] - 0s 44us/step - loss: 94.7477 - val_loss: 89.7637\n",
      "Epoch 30/30\n",
      "11088/11088 [==============================] - 1s 48us/step - loss: 92.8143 - val_loss: 88.7509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4ebabb5d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.01)\n",
    "model = dist_regression_neural_net().compile(loss='mean_squared_error', optimizer=opt)\n",
    "neural_net = dist_regression_neural_net()\n",
    "neural_net.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          batch_size=32, \n",
    "          epochs=30, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_val, y_val):\n",
    "    # training error\n",
    "    pred = model.predict(X_val)\n",
    "\n",
    "    error = y_val[:,np.newaxis]-pred\n",
    "    print 'MSE: {}'.format(np.mean(np.square(error)))\n",
    "\n",
    "    # mean absolute percentage\n",
    "    mean_abs_percentage = np.mean(np.abs(error)/y_val[:,np.newaxis])\n",
    "    print 'Mean Abs Percentage:{}'.format(mean_abs_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1266.25511175\n",
      "Mean Abs Percentage:0.858455399463\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(linear_regressor, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 88.7509389706\n",
      "Mean Abs Percentage:0.114321433865\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(neural_net, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([   0.,    0.,  314.,  185., 1122., 3894., 5116.,  303.,  146.,\n",
       "            8.]),\n",
       "  array([2.000e+00, 1.500e+01, 2.300e+01, 3.860e+02, 1.163e+03, 5.089e+03,\n",
       "         3.240e+03, 1.026e+03, 1.020e+02, 4.200e+01]),\n",
       "  array([   0.,    0.,  357.,   51.,  210., 7340., 1871., 1043.,  119.,\n",
       "           97.]),\n",
       "  array([   0.,    0.,    0.,    0., 1842., 6050., 1342., 1654.,  200.,\n",
       "            0.])],\n",
       " array([-5.98124678, -4.94626002, -3.91127326, -2.8762865 , -1.84129974,\n",
       "        -0.80631298,  0.22867378,  1.26366054,  2.2986473 ,  3.33363406,\n",
       "         4.36862082]),\n",
       " <a list of 4 Lists of Patches objects>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa4eba50850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.hist(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's evaluate a single sample with the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth:\n",
      "(u    262\n",
      "v    252\n",
      "w    341\n",
      "h    326\n",
      "Name: 50, dtype: int64, 43.30380716)\n",
      "prediction: [[44.18644]]\n"
     ]
    }
   ],
   "source": [
    "def eval_single_sample(model, X, y, sample_index=0):\n",
    "    print(\"Ground truth:\")\n",
    "    print(X.loc[sample_index], y.loc[sample_index])\n",
    "    X_single_sample = scaler.transform([X.loc[sample_index].values])\n",
    "    X_single_sample\n",
    "    y_single_sample = y[sample_index]\n",
    "    single_prediction = model.predict(x=X_single_sample)\n",
    "    print(\"prediction: {}\".format(single_prediction))\n",
    "eval_single_sample(neural_net, X,y, sample_index=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: plot predictions vs ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}