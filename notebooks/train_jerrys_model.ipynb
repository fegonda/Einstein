{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/asilomar_nov182017_all.csv')\n",
    "# this is actually [u1, v1, u2, v2]\n",
    "X = df_train[['u','v','w','h']]\n",
    "y = df_train['distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.30)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(NUM_FEATURES*4, input_dim=NUM_FEATURES, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "    model.add(Dense(NUM_FEATURES*4, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11088 samples, validate on 4753 samples\n",
      "Epoch 1/50\n",
      "11088/11088 [==============================] - 1s 67us/step - loss: 993.1515 - val_loss: 169.9807\n",
      "Epoch 2/50\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 159.9531 - val_loss: 153.9270\n",
      "Epoch 3/50\n",
      "11088/11088 [==============================] - 1s 55us/step - loss: 146.2040 - val_loss: 141.5162\n",
      "Epoch 4/50\n",
      "11088/11088 [==============================] - 1s 54us/step - loss: 132.5369 - val_loss: 127.7198\n",
      "Epoch 5/50\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 122.9758 - val_loss: 121.6174\n",
      "Epoch 6/50\n",
      "11088/11088 [==============================] - 1s 46us/step - loss: 116.8196 - val_loss: 116.7652\n",
      "Epoch 7/50\n",
      "11088/11088 [==============================] - 0s 44us/step - loss: 111.7303 - val_loss: 114.5468\n",
      "Epoch 8/50\n",
      "11088/11088 [==============================] - 0s 43us/step - loss: 106.7702 - val_loss: 114.0310\n",
      "Epoch 9/50\n",
      "11088/11088 [==============================] - 0s 44us/step - loss: 104.3725 - val_loss: 112.4984\n",
      "Epoch 10/50\n",
      "11088/11088 [==============================] - 1s 46us/step - loss: 103.1945 - val_loss: 115.8940\n",
      "Epoch 11/50\n",
      "11088/11088 [==============================] - 1s 48us/step - loss: 100.7627 - val_loss: 109.3443\n",
      "Epoch 12/50\n",
      "11088/11088 [==============================] - 1s 51us/step - loss: 99.8710 - val_loss: 110.7671\n",
      "Epoch 13/50\n",
      "11088/11088 [==============================] - 0s 43us/step - loss: 98.5384 - val_loss: 112.5361\n",
      "Epoch 14/50\n",
      "11088/11088 [==============================] - 0s 43us/step - loss: 98.1015 - val_loss: 107.8946\n",
      "Epoch 15/50\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 97.7334 - val_loss: 107.2395\n",
      "Epoch 16/50\n",
      "11088/11088 [==============================] - 1s 49us/step - loss: 95.7773 - val_loss: 110.4949\n",
      "Epoch 17/50\n",
      "11088/11088 [==============================] - 0s 43us/step - loss: 95.7545 - val_loss: 107.7373\n",
      "Epoch 18/50\n",
      "11088/11088 [==============================] - 1s 49us/step - loss: 95.5899 - val_loss: 109.4985\n",
      "Epoch 19/50\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 94.3102 - val_loss: 106.3520\n",
      "Epoch 20/50\n",
      "11088/11088 [==============================] - 1s 69us/step - loss: 93.6369 - val_loss: 109.3280\n",
      "Epoch 21/50\n",
      "11088/11088 [==============================] - 1s 48us/step - loss: 92.4388 - val_loss: 105.9769\n",
      "Epoch 22/50\n",
      "11088/11088 [==============================] - 1s 58us/step - loss: 93.5262 - val_loss: 103.0101\n",
      "Epoch 23/50\n",
      "11088/11088 [==============================] - 1s 55us/step - loss: 91.2964 - val_loss: 103.4908\n",
      "Epoch 24/50\n",
      "11088/11088 [==============================] - 1s 49us/step - loss: 92.0773 - val_loss: 102.5122\n",
      "Epoch 25/50\n",
      "11088/11088 [==============================] - 1s 53us/step - loss: 91.5182 - val_loss: 102.7888\n",
      "Epoch 26/50\n",
      "11088/11088 [==============================] - 1s 46us/step - loss: 89.9126 - val_loss: 106.6405\n",
      "Epoch 27/50\n",
      "11088/11088 [==============================] - 0s 44us/step - loss: 89.3853 - val_loss: 101.2676\n",
      "Epoch 28/50\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 88.7339 - val_loss: 103.6965\n",
      "Epoch 29/50\n",
      "11088/11088 [==============================] - 0s 42us/step - loss: 89.2091 - val_loss: 108.1850\n",
      "Epoch 30/50\n",
      "11088/11088 [==============================] - 0s 43us/step - loss: 89.2718 - val_loss: 98.8563\n",
      "Epoch 31/50\n",
      "11088/11088 [==============================] - 0s 44us/step - loss: 86.1482 - val_loss: 100.1867\n",
      "Epoch 32/50\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 86.4110 - val_loss: 98.8223\n",
      "Epoch 33/50\n",
      "11088/11088 [==============================] - 0s 44us/step - loss: 87.5671 - val_loss: 98.5122\n",
      "Epoch 34/50\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 86.1090 - val_loss: 99.6282\n",
      "Epoch 35/50\n",
      "11088/11088 [==============================] - 0s 44us/step - loss: 84.4038 - val_loss: 101.0434\n",
      "Epoch 36/50\n",
      "11088/11088 [==============================] - 0s 43us/step - loss: 85.5891 - val_loss: 98.3980\n",
      "Epoch 37/50\n",
      "11088/11088 [==============================] - 1s 59us/step - loss: 84.2085 - val_loss: 99.5816\n",
      "Epoch 38/50\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 84.8138 - val_loss: 99.7460\n",
      "Epoch 39/50\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 85.0451 - val_loss: 97.2950\n",
      "Epoch 40/50\n",
      "11088/11088 [==============================] - 1s 46us/step - loss: 83.3281 - val_loss: 102.3344\n",
      "Epoch 41/50\n",
      "11088/11088 [==============================] - 0s 44us/step - loss: 82.6738 - val_loss: 98.6479\n",
      "Epoch 42/50\n",
      "11088/11088 [==============================] - 1s 47us/step - loss: 83.3088 - val_loss: 101.3102\n",
      "Epoch 43/50\n",
      "11088/11088 [==============================] - 1s 53us/step - loss: 83.8222 - val_loss: 98.7728\n",
      "Epoch 44/50\n",
      "11088/11088 [==============================] - 1s 52us/step - loss: 82.8475 - val_loss: 96.4174\n",
      "Epoch 45/50\n",
      "11088/11088 [==============================] - 1s 49us/step - loss: 82.1995 - val_loss: 95.3630\n",
      "Epoch 46/50\n",
      "11088/11088 [==============================] - 0s 44us/step - loss: 81.2973 - val_loss: 95.8939\n",
      "Epoch 47/50\n",
      "11088/11088 [==============================] - 1s 45us/step - loss: 82.5282 - val_loss: 96.3378\n",
      "Epoch 48/50\n",
      "11088/11088 [==============================] - 0s 45us/step - loss: 80.6021 - val_loss: 93.4781\n",
      "Epoch 49/50\n",
      "11088/11088 [==============================] - 1s 46us/step - loss: 81.3748 - val_loss: 96.1737\n",
      "Epoch 50/50\n",
      "11088/11088 [==============================] - 0s 42us/step - loss: 81.0902 - val_loss: 95.4196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f66b4402c90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = dist_regression_model()\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          batch_size=32, \n",
    "          epochs=50, \n",
    "          validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 95.4196220838\n",
      "Mean Abs Percentage:0.115043921209\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_val, y_val):\n",
    "    # training error\n",
    "    pred = model.predict(X_val)\n",
    "\n",
    "    error = y_val[:,np.newaxis]-pred\n",
    "    print 'MSE: {}'.format(np.mean(np.square(error)))\n",
    "\n",
    "    # mean absolute percentage\n",
    "    mean_abs_percentage = np.mean(np.abs(error)/y_val[:,np.newaxis])\n",
    "    print 'Mean Abs Percentage:{}'.format(mean_abs_percentage)\n",
    "\n",
    "evaluate_model(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.41962208378774\n",
      "0.11504392120861687\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "X_val_np = X_val\n",
    "y_val_np = y_val\n",
    "pred = model.predict(X_val_np)\n",
    "\n",
    "# mean square error\n",
    "error = y_val_np[:,np.newaxis]-pred\n",
    "print np.mean(np.square(error))\n",
    "\n",
    "# mean absolute percentage\n",
    "mean_abs_percentage = np.mean(np.abs(error)/y_val_np[:,np.newaxis])\n",
    "print mean_abs_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.31268547e+00]\n",
      " [ 6.89054445e-03]\n",
      " [-2.67833434e+00]\n",
      " [ 7.25586408e+00]\n",
      " [-1.17855883e-01]\n",
      " [ 2.95889232e+00]\n",
      " [ 2.49069443e-01]\n",
      " [ 1.66301307e+00]\n",
      " [-3.16023579e-01]\n",
      " [ 2.53417482e+00]]\n"
     ]
    }
   ],
   "source": [
    "print error[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "[[13.313145]]\n"
     ]
    }
   ],
   "source": [
    "bbox = np.array([[147.,  295.,147+331.,295.+173.]],np.float32)\n",
    "bbox = scaler.transform(bbox)\n",
    "print bbox.shape\n",
    "print model.predict(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([107., 255., 402., 475.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(X_train[100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1473077,  4.6086993, -4.7980194, -5.175077 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox = np.array([[240,300,46,39]],np.float32)\n",
    "scaler.transform(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}